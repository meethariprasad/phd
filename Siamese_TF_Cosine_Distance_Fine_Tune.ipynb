{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese TF Cosine Distance Fine Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meethariprasad/research_works/blob/master/Siamese_TF_Cosine_Distance_Fine_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90S3uGNW9sMO",
        "colab_type": "text"
      },
      "source": [
        "###### Author: Hari Prasad, This work is as part of providing simple examples in the world of complicated examples. Have fun!\n",
        "###### Licence: Free to Distribute and Modify. You can quote this github reference for sure. :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94h6dYJrrUtU",
        "colab_type": "code",
        "outputId": "081ce035-527c-4ed2-a17d-57f1df9ccf64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install tensorflow==2.1.0rc0\n",
        "import tensorflow as tf\n",
        "print (tf.__version__)\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmRkXOdiIrGg",
        "colab_type": "code",
        "outputId": "c343cf40-f106-400b-bee4-53cc4909fbe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (\"Following is simple self explatory code of how dot layer works as cosine similiarity between two vectors, if normalize = True set\")\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "x=np.asarray([-1.,-1.,-1])\n",
        "x=np.reshape(x,(1,3))\n",
        "y=np.asarray([1.,1.,1.])\n",
        "y=np.reshape(y,(1,3))\n",
        "tf.keras.layers.Dot(axes=-1,normalize=True)([x,y]).numpy()[0][0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following is simple self explatory code of how dot layer works as cosine similiarity between two vectors, if normalize = True set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0000000000000002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNX6jbv40iyV",
        "colab_type": "code",
        "outputId": "b4be2b9d-fd59-4315-e877-83f609c5aa73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# !pip install tensorflow==2.1.0rc0\n",
        "import tensorflow as tf\n",
        "print (tf.__version__)\n",
        "tf.keras.backend.clear_session()\n",
        "import gc\n",
        "try:\n",
        "  del model\n",
        "except:\n",
        "  pass\n",
        "gc.collect()\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "huburl = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
        "fine_tuned_module_object = hub.load(huburl)\n",
        "shared_embedding_layer = hub.KerasLayer(fine_tuned_module_object,trainable=True)\n",
        "\n",
        "left_input = keras.Input(shape=(), dtype=tf.string)\n",
        "right_input = keras.Input(shape=(), dtype=tf.string)\n",
        "\n",
        "embedding_left_output= shared_embedding_layer(left_input)\n",
        "embedding_right_output= shared_embedding_layer(right_input)\n",
        "\n",
        "cosine_similiarity=tf.keras.layers.Dot(axes=-1,normalize=True)([embedding_left_output,embedding_right_output])\n",
        "\n",
        "#We are using acos so that highly similiar sentences can have well \n",
        "#seperation. So we are not using:\n",
        "#cos_distance=1-cosine_similiarity\n",
        "#https://math.stackexchange.com/questions/2874940/cosine-similarity-vs-angular-distance?newreg=02fd1e16a9164cbba05197b28d353409\n",
        "clip_cosine_similarities = tf.clip_by_value(cosine_similiarity, -1.0, 1.0)\n",
        "import math as m\n",
        "pi = tf.constant(m.pi,dtype= tf.float64)\n",
        "cos_distance = 1.0 - (tf.acos(clip_cosine_similarities)/pi)\n",
        "#Acos Range (0 to Pi (3.14)/pi radians, with 0 as closest 1 as farthest )\n",
        "#cos_distance range=1-0=>1 to 1-1=>0, with 1 being nearest and 0 being farthest\n",
        "#http://mathonweb.com/help_ebook/html/functions_2.htm\n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.Model([left_input,right_input], cos_distance)\n",
        "#Define Optimizer\n",
        "\n",
        "optim =tf.compat.v1.train.ProximalAdagradOptimizer(learning_rate=0.0001\n",
        "                                                   ,l1_regularization_strength=0.0,\n",
        "                                                   l2_regularization_strength=0.01\n",
        "                                                   )\n",
        "model.compile(optimizer=optim, loss='mse')\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, to_file='my_model.png')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        (None, 512)          256797824   input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1)            0           keras_layer[0][0]                \n",
            "                                                                 keras_layer[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_clip_by_value/Minim [(None, 1)]          0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_clip_by_value (Tens [(None, 1)]          0           tf_op_layer_clip_by_value/Minimum\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Acos (TensorFlowOpL [(None, 1)]          0           tf_op_layer_clip_by_value[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow [(None, 1)]          0           tf_op_layer_Acos[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_truediv[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 256,797,824\n",
            "Trainable params: 256,797,824\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAALlCAIAAACJr0JiAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n8BhCHACAx/4fjCKuidelhjsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9qHUv-I59_9",
        "colab_type": "text"
      },
      "source": [
        "### Arc Cosine Distance Target Value Explanation\n",
        "\n",
        "We are using Arc Cosine based distance as it is capable of giving distinct scores even for smaller angles compared to plain cosine distance.\n",
        "\n",
        "As you you can see range of arccosine is in 0 to Pi for domain of similiarity between 1 to -1, 1 being highly similiar.\n",
        "\n",
        "Hence 1-arccos distance is 1-0->1 to 1-(pi) (which is negative quantity)\n",
        "\n",
        "To make it between 0 to 1, we are dividing 1-arccos by pi as given in paper.\n",
        "\n",
        "It means the distance is now between 1 to (1-1)=0, with 1 which corresponds to cosine similiarity 1 and 0 correspongs to -1 (highly dissimiliar).\n",
        "\n",
        "Hence now you can define any sentence similiarity in the range of 1 to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLtF-Xrk75SR",
        "colab_type": "code",
        "outputId": "e1c4984e-838f-4c02-c32a-1c3e3951f0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Inputs\n",
        "import numpy as np\n",
        "text_list=[[\"Man is going to Moon\",\"Education is greatest gift to humanity\"],\n",
        "           [\"Man achieved great feat in apollo mission\",\"Literacy is important for civilization\"]]\n",
        "\n",
        "#Model Input Preperation as Numpy array\n",
        "left_inputs=np.asarray(text_list[0])\n",
        "right_inputs=np.asarray(text_list[1])\n",
        "#1 if we inputs are semantically similiar, 0 if not. \n",
        "#Check the distance function defined as 1-arccos(similiarity)/pi which has range between 1,0 for domain 0 to 1\n",
        "similiarity=np.asarray([1,1])\n",
        "\n",
        "left_inputs=left_inputs.reshape(left_inputs.shape[0],)\n",
        "right_inputs=right_inputs.reshape(right_inputs.shape[0],)\n",
        "\n",
        "left_inputs.shape,right_inputs.shape,similiarity.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2,), (2,), (2,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJNH5d4UE6Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_similiarity(target_text_embed,text_to_compare_embed):\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    similiarity=cosine_similarity(target_text_embed,text_to_compare_embed)\n",
        "    similiarity=pd.DataFrame(similiarity)\n",
        "    return similiarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16tBBRBJNNtu",
        "colab_type": "code",
        "outputId": "dd19edc5-96a6-4889-eca2-0df4c523b726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Model Fit\n",
        "from keras.callbacks import Callback\n",
        "class stopAtLossValue(Callback):\n",
        "  import numpy as np\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "    THR = 0 #Assign THR with the value at which you want to stop training.\n",
        "    if np.around(logs.get('loss'),decimals=1) == THR:\n",
        "      self.model.stop_training = True\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "model.fit([left_inputs,right_inputs],similiarity,epochs=300,callbacks=[stopAtLossValue()])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2 samples\n",
            "Epoch 1/300\n",
            "2/2 [==============================] - 7s 4s/sample - loss: 0.1283\n",
            "Epoch 2/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1283\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1283\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1283\n",
            "Epoch 5/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1283\n",
            "Epoch 6/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1282\n",
            "Epoch 7/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1282\n",
            "Epoch 8/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1282\n",
            "Epoch 9/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1282\n",
            "Epoch 10/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1282\n",
            "Epoch 11/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1282\n",
            "Epoch 12/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1282\n",
            "Epoch 13/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1282\n",
            "Epoch 14/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1282\n",
            "Epoch 15/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1282\n",
            "Epoch 16/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1282\n",
            "Epoch 17/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1281\n",
            "Epoch 18/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1281\n",
            "Epoch 19/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1281\n",
            "Epoch 20/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1281\n",
            "Epoch 21/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1281\n",
            "Epoch 22/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1281\n",
            "Epoch 23/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1281\n",
            "Epoch 24/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1281\n",
            "Epoch 25/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1281\n",
            "Epoch 26/300\n",
            "2/2 [==============================] - 0s 19ms/sample - loss: 0.1281\n",
            "Epoch 27/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1281\n",
            "Epoch 28/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 29/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 30/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1280\n",
            "Epoch 31/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 32/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 33/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1280\n",
            "Epoch 34/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 35/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1280\n",
            "Epoch 36/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1280\n",
            "Epoch 37/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1280\n",
            "Epoch 38/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1280\n",
            "Epoch 39/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 40/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 41/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 42/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1279\n",
            "Epoch 43/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1279\n",
            "Epoch 44/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 45/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 46/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1279\n",
            "Epoch 47/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1279\n",
            "Epoch 48/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1279\n",
            "Epoch 49/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1279\n",
            "Epoch 50/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1278\n",
            "Epoch 51/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1278\n",
            "Epoch 52/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1278\n",
            "Epoch 53/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1278\n",
            "Epoch 54/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1278\n",
            "Epoch 55/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1278\n",
            "Epoch 56/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1278\n",
            "Epoch 57/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1278\n",
            "Epoch 58/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1278\n",
            "Epoch 59/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1278\n",
            "Epoch 60/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1278\n",
            "Epoch 61/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 62/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 63/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 64/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1277\n",
            "Epoch 65/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 66/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1277\n",
            "Epoch 67/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 68/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 69/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 70/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 71/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1277\n",
            "Epoch 72/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1276\n",
            "Epoch 73/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1276\n",
            "Epoch 74/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 75/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1276\n",
            "Epoch 76/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1276\n",
            "Epoch 77/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 78/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 79/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 80/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1276\n",
            "Epoch 81/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 82/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1276\n",
            "Epoch 83/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1276\n",
            "Epoch 84/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 85/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1275\n",
            "Epoch 86/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1275\n",
            "Epoch 87/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 88/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 89/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1275\n",
            "Epoch 90/300\n",
            "2/2 [==============================] - 0s 18ms/sample - loss: 0.1275\n",
            "Epoch 91/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 92/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 93/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1275\n",
            "Epoch 94/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1275\n",
            "Epoch 95/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1274\n",
            "Epoch 96/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1274\n",
            "Epoch 97/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1274\n",
            "Epoch 98/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1274\n",
            "Epoch 99/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1274\n",
            "Epoch 100/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1274\n",
            "Epoch 101/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1274\n",
            "Epoch 102/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1274\n",
            "Epoch 103/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1274\n",
            "Epoch 104/300\n",
            "2/2 [==============================] - 0s 10ms/sample - loss: 0.1274\n",
            "Epoch 105/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1274\n",
            "Epoch 106/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 107/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 108/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1273\n",
            "Epoch 109/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 110/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 111/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1273\n",
            "Epoch 112/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 113/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1273\n",
            "Epoch 114/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1273\n",
            "Epoch 115/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1273\n",
            "Epoch 116/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1273\n",
            "Epoch 117/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1272\n",
            "Epoch 118/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1272\n",
            "Epoch 119/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1272\n",
            "Epoch 120/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1272\n",
            "Epoch 121/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1272\n",
            "Epoch 122/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1272\n",
            "Epoch 123/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1272\n",
            "Epoch 124/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1272\n",
            "Epoch 125/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1272\n",
            "Epoch 126/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1272\n",
            "Epoch 127/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1272\n",
            "Epoch 128/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1271\n",
            "Epoch 129/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1271\n",
            "Epoch 130/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1271\n",
            "Epoch 131/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1271\n",
            "Epoch 132/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1271\n",
            "Epoch 133/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1271\n",
            "Epoch 134/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1271\n",
            "Epoch 135/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1271\n",
            "Epoch 136/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1271\n",
            "Epoch 137/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1271\n",
            "Epoch 138/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1271\n",
            "Epoch 139/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1270\n",
            "Epoch 140/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1270\n",
            "Epoch 141/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1270\n",
            "Epoch 142/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1270\n",
            "Epoch 143/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1270\n",
            "Epoch 144/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1270\n",
            "Epoch 145/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1270\n",
            "Epoch 146/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1270\n",
            "Epoch 147/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1270\n",
            "Epoch 148/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1270\n",
            "Epoch 149/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1270\n",
            "Epoch 150/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1269\n",
            "Epoch 151/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1269\n",
            "Epoch 152/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1269\n",
            "Epoch 153/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1269\n",
            "Epoch 154/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1269\n",
            "Epoch 155/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1269\n",
            "Epoch 156/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1269\n",
            "Epoch 157/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1269\n",
            "Epoch 158/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1269\n",
            "Epoch 159/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1269\n",
            "Epoch 160/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1269\n",
            "Epoch 161/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1268\n",
            "Epoch 162/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1268\n",
            "Epoch 163/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1268\n",
            "Epoch 164/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1268\n",
            "Epoch 165/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1268\n",
            "Epoch 166/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1268\n",
            "Epoch 167/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1268\n",
            "Epoch 168/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1268\n",
            "Epoch 169/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1268\n",
            "Epoch 170/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1268\n",
            "Epoch 171/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1268\n",
            "Epoch 172/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1268\n",
            "Epoch 173/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1267\n",
            "Epoch 174/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 175/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1267\n",
            "Epoch 176/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 177/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1267\n",
            "Epoch 178/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1267\n",
            "Epoch 179/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 180/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 181/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 182/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1267\n",
            "Epoch 183/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1267\n",
            "Epoch 184/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1266\n",
            "Epoch 185/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1266\n",
            "Epoch 186/300\n",
            "2/2 [==============================] - 0s 18ms/sample - loss: 0.1266\n",
            "Epoch 187/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1266\n",
            "Epoch 188/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1266\n",
            "Epoch 189/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1266\n",
            "Epoch 190/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1266\n",
            "Epoch 191/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1266\n",
            "Epoch 192/300\n",
            "2/2 [==============================] - 0s 10ms/sample - loss: 0.1266\n",
            "Epoch 193/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1266\n",
            "Epoch 194/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1266\n",
            "Epoch 195/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 196/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 197/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 198/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1265\n",
            "Epoch 199/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 200/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 201/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1265\n",
            "Epoch 202/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 203/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1265\n",
            "Epoch 204/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1265\n",
            "Epoch 205/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1265\n",
            "Epoch 206/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1264\n",
            "Epoch 207/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1264\n",
            "Epoch 208/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1264\n",
            "Epoch 209/300\n",
            "2/2 [==============================] - 0s 20ms/sample - loss: 0.1264\n",
            "Epoch 210/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1264\n",
            "Epoch 211/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1264\n",
            "Epoch 212/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1264\n",
            "Epoch 213/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1264\n",
            "Epoch 214/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1264\n",
            "Epoch 215/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1264\n",
            "Epoch 216/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1264\n",
            "Epoch 217/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1263\n",
            "Epoch 218/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1263\n",
            "Epoch 219/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1263\n",
            "Epoch 220/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1263\n",
            "Epoch 221/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1263\n",
            "Epoch 222/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1263\n",
            "Epoch 223/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1263\n",
            "Epoch 224/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1263\n",
            "Epoch 225/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1263\n",
            "Epoch 226/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1263\n",
            "Epoch 227/300\n",
            "2/2 [==============================] - 0s 16ms/sample - loss: 0.1263\n",
            "Epoch 228/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1263\n",
            "Epoch 229/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1262\n",
            "Epoch 230/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1262\n",
            "Epoch 231/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1262\n",
            "Epoch 232/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1262\n",
            "Epoch 233/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1262\n",
            "Epoch 234/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1262\n",
            "Epoch 235/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1262\n",
            "Epoch 236/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1262\n",
            "Epoch 237/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1262\n",
            "Epoch 238/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1262\n",
            "Epoch 239/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1262\n",
            "Epoch 240/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 241/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 242/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 243/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 244/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 245/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1261\n",
            "Epoch 246/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1261\n",
            "Epoch 247/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 248/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 249/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 250/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1261\n",
            "Epoch 251/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1260\n",
            "Epoch 252/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1260\n",
            "Epoch 253/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1260\n",
            "Epoch 254/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1260\n",
            "Epoch 255/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1260\n",
            "Epoch 256/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1260\n",
            "Epoch 257/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1260\n",
            "Epoch 258/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1260\n",
            "Epoch 259/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1260\n",
            "Epoch 260/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1260\n",
            "Epoch 261/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1260\n",
            "Epoch 262/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1260\n",
            "Epoch 263/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1259\n",
            "Epoch 264/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1259\n",
            "Epoch 265/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 266/300\n",
            "2/2 [==============================] - 0s 12ms/sample - loss: 0.1259\n",
            "Epoch 267/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 268/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 269/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 270/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 271/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1259\n",
            "Epoch 272/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1259\n",
            "Epoch 273/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1259\n",
            "Epoch 274/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1258\n",
            "Epoch 275/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1258\n",
            "Epoch 276/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1258\n",
            "Epoch 277/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1258\n",
            "Epoch 278/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1258\n",
            "Epoch 279/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1258\n",
            "Epoch 280/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1258\n",
            "Epoch 281/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1258\n",
            "Epoch 282/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1258\n",
            "Epoch 283/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1258\n",
            "Epoch 284/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1258\n",
            "Epoch 285/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1257\n",
            "Epoch 286/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1257\n",
            "Epoch 287/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1257\n",
            "Epoch 288/300\n",
            "2/2 [==============================] - 0s 17ms/sample - loss: 0.1257\n",
            "Epoch 289/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1257\n",
            "Epoch 290/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1257\n",
            "Epoch 291/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1257\n",
            "Epoch 292/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1257\n",
            "Epoch 293/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1257\n",
            "Epoch 294/300\n",
            "2/2 [==============================] - 0s 11ms/sample - loss: 0.1257\n",
            "Epoch 295/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1257\n",
            "Epoch 296/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1256\n",
            "Epoch 297/300\n",
            "2/2 [==============================] - 0s 13ms/sample - loss: 0.1256\n",
            "Epoch 298/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1256\n",
            "Epoch 299/300\n",
            "2/2 [==============================] - 0s 15ms/sample - loss: 0.1256\n",
            "Epoch 300/300\n",
            "2/2 [==============================] - 0s 14ms/sample - loss: 0.1256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a7f2ed048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXtrye20SNrH",
        "colab_type": "code",
        "outputId": "c98789d3-d376-4d64-9cdb-faca15fa408f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print (text_list)\n",
        "try:\n",
        "  text_list=sum(text_list, [])\n",
        "except:\n",
        "  pass\n",
        "\n",
        "embeddings = fine_tuned_module_object(text_list)\n",
        "\n",
        "# print (embeddings.numpy())\n",
        "\n",
        "embed_target=embeddings.numpy()\n",
        "import pandas as pd\n",
        "doc_embed = pd.DataFrame(data=embed_target)\n",
        "doc_embed.index=text_list\n",
        "\n",
        "\n",
        "\n",
        "finetuned_similiarity=get_similiarity(doc_embed,doc_embed)\n",
        "# np.fill_diagonal(sim.values, 0)\n",
        "finetuned_similiarity.index=text_list\n",
        "finetuned_similiarity.columns=text_list\n",
        "print (\"With Fine Tune\")\n",
        "finetuned_similiarity"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Man is going to Moon', 'Education is greatest gift to humanity'], ['Man achieved great feat in apollo mission', 'Literacy is important for civilization']]\n",
            "With Fine Tune\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Man is going to Moon</th>\n",
              "      <th>Education is greatest gift to humanity</th>\n",
              "      <th>Man achieved great feat in apollo mission</th>\n",
              "      <th>Literacy is important for civilization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Man is going to Moon</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.112738</td>\n",
              "      <td>0.433109</td>\n",
              "      <td>0.107581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Education is greatest gift to humanity</th>\n",
              "      <td>0.112738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171568</td>\n",
              "      <td>0.450143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Man achieved great feat in apollo mission</th>\n",
              "      <td>0.433109</td>\n",
              "      <td>0.171568</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.058195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Literacy is important for civilization</th>\n",
              "      <td>0.107581</td>\n",
              "      <td>0.450143</td>\n",
              "      <td>0.058195</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Man is going to Moon  ...  Literacy is important for civilization\n",
              "Man is going to Moon                                   1.000000  ...                                0.107581\n",
              "Education is greatest gift to humanity                 0.112738  ...                                0.450143\n",
              "Man achieved great feat in apollo mission              0.433109  ...                                0.058195\n",
              "Literacy is important for civilization                 0.107581  ...                                1.000000\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp4KFVABTCMm",
        "colab_type": "code",
        "outputId": "75605cb6-3f3a-4df3-de04-1561014ca1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#Without fine tune: Similiarity\n",
        "########################################\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "un_tuned_module_object = hub.load(huburl)\n",
        "try:\n",
        "  text_list=sum(text_list, [])\n",
        "except:\n",
        "  pass\n",
        "\n",
        "embeddings = un_tuned_module_object(text_list)\n",
        "\n",
        "embed_target=embeddings.numpy()\n",
        "import pandas as pd\n",
        "doc_embed_global = pd.DataFrame(data=embed_target)\n",
        "doc_embed_global.index=text_list\n",
        "########################################\n",
        "global_similiarity=get_similiarity(doc_embed_global,doc_embed_global)\n",
        "# np.fill_diagonal(sim.values, 0)\n",
        "global_similiarity.index=text_list\n",
        "global_similiarity.columns=text_list\n",
        "\n",
        "print (\"Without Fine Tune\")\n",
        "global_similiarity"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Fine Tune\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Man is going to Moon</th>\n",
              "      <th>Education is greatest gift to humanity</th>\n",
              "      <th>Man achieved great feat in apollo mission</th>\n",
              "      <th>Literacy is important for civilization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Man is going to Moon</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.104139</td>\n",
              "      <td>0.421958</td>\n",
              "      <td>0.099204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Education is greatest gift to humanity</th>\n",
              "      <td>0.104139</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.163523</td>\n",
              "      <td>0.439952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Man achieved great feat in apollo mission</th>\n",
              "      <td>0.421958</td>\n",
              "      <td>0.163523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.049431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Literacy is important for civilization</th>\n",
              "      <td>0.099204</td>\n",
              "      <td>0.439952</td>\n",
              "      <td>0.049431</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Man is going to Moon  ...  Literacy is important for civilization\n",
              "Man is going to Moon                                   1.000000  ...                                0.099204\n",
              "Education is greatest gift to humanity                 0.104139  ...                                0.439952\n",
              "Man achieved great feat in apollo mission              0.421958  ...                                0.049431\n",
              "Literacy is important for civilization                 0.099204  ...                                1.000000\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fchzX1wRTwh",
        "colab_type": "code",
        "outputId": "c43ed57c-49aa-4f28-9ec7-6380ba7fced4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (\"Following code can be used to export and reuse the fine tuned module from local system.\")\n",
        "import os\n",
        "#Set export to true to export fine tuned model to module_export_dir_name\n",
        "export=False\n",
        "if (export):\n",
        "  module_export_dir_name='finetuned_model_export'\n",
        "  #Creating module export directory in current directory. You can change wherever you need.\n",
        "  os.makedirs(module_export_dir_name,exist_ok=True)\n",
        "  export_module_dir = os.path.join(os.getcwd(), module_export_dir_name)\n",
        "  tf.saved_model.save(fine_tuned_module_object, export_module_dir)\n",
        "  fine_tuned_module_dir=os.path.join(os.getcwd(),module_export_dir_name)\n",
        "\n",
        "  loaded_module_obj = hub.load(fine_tuned_module_dir)\n",
        "  embeddings = loaded_module_obj(text_list)\n",
        "\n",
        "  embed_target=embeddings.numpy()\n",
        "  import pandas as pd\n",
        "  doc_embed = pd.DataFrame(data=embed_target)\n",
        "  doc_embed.index=text_list\n",
        "\n",
        "\n",
        "  finetuned_similiarity_loaded=get_similiarity(doc_embed,doc_embed)\n",
        "  # np.fill_diagonal(sim.values, 0)\n",
        "  finetuned_similiarity_loaded.index=text_list\n",
        "  finetuned_similiarity_loaded.columns=text_list\n",
        "  print (\"With Fine Tune and Exported\")\n",
        "  finetuned_similiarity_loaded\n",
        "else:\n",
        "  print (\"No Export Selected\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following code can be used to export and reuse the fine tuned module from local system.\n",
            "No Export Selected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejDq0GQO2bL0",
        "colab_type": "text"
      },
      "source": [
        "### *Following Sections are reused from Google Universal Sentence Embedding Evaluation. Thanks to TF Hub Authors.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgBfRfzRpZBh",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation: STS (Semantic Textual Similarity) Benchmark\n",
        "\n",
        "The [**STS Benchmark**](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) provides an intristic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q5nuBbI1iFQR"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q14v1nCnpYTy",
        "colab_type": "code",
        "outputId": "9b22a6c2-e799-493f-9716-66a6bc6efa36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas\n",
        "import scipy\n",
        "import math\n",
        "import csv\n",
        "\n",
        "sts_dataset = tf.keras.utils.get_file(\n",
        "    fname=\"Stsbenchmark.tar.gz\",\n",
        "    origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
        "    extract=True)\n",
        "sts_dev = pandas.read_table(\n",
        "    os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"),\n",
        "    error_bad_lines=False,\n",
        "    skip_blank_lines=True,\n",
        "    usecols=[4, 5, 6],\n",
        "    names=[\"sim\", \"sent_1\", \"sent_2\"])\n",
        "sts_test = pandas.read_table(\n",
        "    os.path.join(\n",
        "        os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"),\n",
        "    error_bad_lines=False,\n",
        "    quoting=csv.QUOTE_NONE,\n",
        "    skip_blank_lines=True,\n",
        "    usecols=[4, 5, 6],\n",
        "    names=[\"sim\", \"sent_1\", \"sent_2\"])\n",
        "# cleanup some NaN values in sts_dev\n",
        "sts_dev = sts_dev[[isinstance(s, str) for s in sts_dev['sent_2']]]\n",
        "print (sts_dev.shape,sts_test.shape)\n",
        "sts_dev.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1468, 3) (1379, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>sent_1</th>\n",
              "      <th>sent_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.00</td>\n",
              "      <td>A man with a hard hat is dancing.</td>\n",
              "      <td>A man wearing a hard hat is dancing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.75</td>\n",
              "      <td>A young child is riding a horse.</td>\n",
              "      <td>A child is riding a horse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.00</td>\n",
              "      <td>A man is feeding a mouse to a snake.</td>\n",
              "      <td>The man is feeding a mouse to the snake.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.40</td>\n",
              "      <td>A woman is playing the guitar.</td>\n",
              "      <td>A man is playing guitar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.75</td>\n",
              "      <td>A woman is playing the flute.</td>\n",
              "      <td>A man is playing a flute.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sim  ...                                    sent_2\n",
              "0  5.00  ...      A man wearing a hard hat is dancing.\n",
              "1  4.75  ...                A child is riding a horse.\n",
              "2  5.00  ...  The man is feeding a mouse to the snake.\n",
              "3  2.40  ...                  A man is playing guitar.\n",
              "4  2.75  ...                 A man is playing a flute.\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8OKy8WhnKRe_"
      },
      "source": [
        "### Evaluate Sentence Embeddings for Fine Tuned Module\n",
        "\n",
        "Fine tuning must not too much reduce the OOB Module Corelation Score, indicating we have not much compromised  generalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-q2r7jyZGb7",
        "cellView": "both",
        "outputId": "148f5edd-b0b9-4a0b-92a8-b15feaeb34e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sts_data = sts_test #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\n",
        "\n",
        "def run_sts_benchmark(batch,module_object):\n",
        "  sts_encode1 = tf.nn.l2_normalize(module_object(tf.constant(batch['sent_1'].tolist())), axis=1)\n",
        "  sts_encode2 = tf.nn.l2_normalize(module_object(tf.constant(batch['sent_2'].tolist())), axis=1)\n",
        "  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
        "  clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n",
        "  scores = 1.0 - tf.acos(clip_cosine_similarities)\n",
        "  \"\"\"Returns the similarity scores\"\"\"\n",
        "  return scores\n",
        "\n",
        "dev_scores = sts_data['sim'].tolist()\n",
        "scores = []\n",
        "\n",
        "module_object=un_tuned_module_object\n",
        "\n",
        "for batch in np.array_split(sts_data, 10):\n",
        "  scores.extend(run_sts_benchmark(batch,module_object))\n",
        "\n",
        "pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
        "print('Untuned Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
        "    pearson_correlation[0], pearson_correlation[1]))\n",
        "\n",
        "\n",
        "##With Fune#\n",
        "module_object=fine_tuned_module_object\n",
        "scores = []\n",
        "for batch in np.array_split(sts_data, 10):\n",
        "  scores.extend(run_sts_benchmark(batch,module_object))\n",
        "\n",
        "pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
        "print('Fine Tuned Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
        "    pearson_correlation[0], pearson_correlation[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Untuned Pearson correlation coefficient = 0.7821121693112975\n",
            "p-value = 3.811544425526969e-285\n",
            "Fine Tuned Pearson correlation coefficient = 0.7819043155111678\n",
            "p-value = 6.783365875124484e-285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ69oPu5bOS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}