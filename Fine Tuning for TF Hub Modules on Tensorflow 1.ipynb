{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow, hub versions 1.12.0 0.2.0\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_experimental_distribute': None, '_protocol': None, '_device_fn': None, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f95587249b0>, '_task_id': 0, '_tf_random_seed': None, '_eval_distribute': None, '_num_worker_replicas': 1, '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_service': None, '_model_dir': '/media/sf_codebase/experiment/modeldir', '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_is_chief': True, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "(?, 128)\n",
      "Tensor(\"Const_1:0\", shape=(3,), dtype=int32, device=/device:CPU:0)\n",
      "I am in mode: train\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /media/sf_codebase/experiment/modeldir/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0841455, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /media/sf_codebase/experiment/modeldir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5514447.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "(?, 128)\n",
      "None\n",
      "I am in mode: infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Restoring parameters from /media/sf_codebase/experiment/modeldir/model.ckpt-10\n",
      "INFO:tensorflow:Exported TF-Hub module to: b\"/media/sf_codebase/experiment/export/temp-b'1575045661'/my_module\"\n"
     ]
    }
   ],
   "source": [
    "# # Custom Estimator and export\n",
    "# https://github.com/tensorflow/hub/issues/132\n",
    "#nnlm_module_path,uni_sent_module_path\n",
    "#uni_sent_module_path='/media/sf_codebase/modules/nnlm-en-dim128'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_hub as hub\n",
    "print (\"Tensorflow, hub versions\",tf.__version__,hub.__version__)\n",
    "\n",
    "_TEXT_FEATURE_NAME = \"text\"\n",
    "_EXPORT_MODULE_NAME = \"unifinetune\"\n",
    "\n",
    "uni_sent_module_path=\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
    "\n",
    "def _input_fn():\n",
    "    \"\"\"An input fn.\"\"\"\n",
    "    features = {\n",
    "        _TEXT_FEATURE_NAME: tf.constant([\n",
    "          \"hadoop hive\", \"asp net\",\"js javascript nodejs\"]),\n",
    "    }\n",
    "    labels = tf.constant([0,1,2])\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def _serving_input_fn():\n",
    "    \"\"\"A serving input fn.\"\"\"\n",
    "    text_features = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features={_TEXT_FEATURE_NAME: text_features},\n",
    "        receiver_tensors=text_features)\n",
    "\n",
    "def _get_model_fn(register_module=False):\n",
    "    def _model_fn(features, labels, mode):\n",
    "        \"\"\"A model_fn that uses a mock TF-Hub module.\"\"\"\n",
    "#         del labels\n",
    "        \n",
    "        hub_module = hub.Module(uni_sent_module_path,trainable=True)\n",
    "        hub.register_module_for_export(hub_module, \"my_module\")\n",
    "        \n",
    "        embedding = hub_module(features[\"text\"])\n",
    "        print (embedding.shape)\n",
    "        first_layer = tf.layers.dense(inputs=embedding, units=100, activation=tf.nn.relu)\n",
    "        second_layer = tf.layers.dense(inputs=first_layer, units=100, activation=tf.nn.relu)\n",
    "        logits = tf.layers.dense(inputs=second_layer, units=3, activation=tf.nn.softmax)\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "#         labels = tf.cast(labels, tf.int64)\n",
    "#         print (labels.shape,logits.shape,predictions.shape)\n",
    "        labels=labels\n",
    "        print (labels)\n",
    "        # Create an optimizer that will take care of the Gradient Descent\n",
    "        optimizer = tf.train.AdamOptimizer(0.01)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            print (\"I am in mode:\",mode)\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)\n",
    "        \n",
    "        # Create the training operation\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels,logits)\n",
    "        train_op = optimizer.minimize(loss,tf.train.get_global_step())\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            print (\"I am in mode:\",mode)\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions,loss=loss,train_op=train_op)\n",
    "    return _model_fn\n",
    "\n",
    "import os\n",
    "os.makedirs(\"modeldir\", exist_ok=True)\n",
    "os.makedirs(\"export\", exist_ok=True)\n",
    "model_dir = os.path.join(os.getcwd(),'modeldir')\n",
    "export_base_dir = os.path.join(os.getcwd(), \"export\")\n",
    "estimator = tf.estimator.Estimator(_get_model_fn(register_module=True),\n",
    "                                       model_dir=model_dir)\n",
    "estimator.train(input_fn=_input_fn, steps=10)\n",
    "exporter = hub.LatestModuleExporter(\"exporter_name\", _serving_input_fn)\n",
    "export_dir = exporter.export(estimator=estimator,export_path=export_base_dir,checkpoint_path=estimator.latest_checkpoint(),eval_result=None,is_the_final_export=None)\n",
    "exported_module_path=os.path.join(export_dir.decode(\"utf-8\"),\"my_module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With finetuning we expect the related technologies should come near to each other,reflecting local corpus\n",
      "module path /media/sf_codebase/experiment/export/1575045661/my_module\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>hive</td>\n",
       "      <td>0.449132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hive</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.449132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asp</td>\n",
       "      <td>net</td>\n",
       "      <td>0.481343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net</td>\n",
       "      <td>asp</td>\n",
       "      <td>0.481343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>js</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.673985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>javascript</td>\n",
       "      <td>js</td>\n",
       "      <td>0.673985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nodejs</td>\n",
       "      <td>js</td>\n",
       "      <td>0.517689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1         2\n",
       "0  hadoop      hive        0.449132\n",
       "1  hive        hadoop      0.449132\n",
       "2  asp         net         0.481343\n",
       "3  net         asp         0.481343\n",
       "4  js          javascript  0.673985\n",
       "5  javascript  js          0.673985\n",
       "6  nodejs      js          0.517689"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"With finetuning we expect the related technologies should come near to each other,reflecting local corpus\")\n",
    "\n",
    "# %%time\n",
    "# #https://github.com/tensorflow/hub/blob/master/docs/common_issues.md#running-inference-on-a-pre-initialized-module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "test=pd.read_excel('test.xlsx')\n",
    "test=test['Curated Risks'].values.tolist()\n",
    "test=[\"hadoop\",\"hive\", \"asp\", \"net\",\"js\",\"javascript\",\"nodejs\"]\n",
    "exported_module_path=exported_module_path\n",
    "print ('module path',exported_module_path)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Create graph and finalize (finalizing optional but recommended).\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  # We will be feeding 1D tensors of text into the graph.\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  #nnlm-en-dim128,universal_sentence_encoder_large_3\n",
    "  embed = hub.Module(exported_module_path)\n",
    "  embedded_text = embed(text_input)\n",
    "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "# Create session and initialize.\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_op)\n",
    "def get_embeddings(embedded_text,session,text):\n",
    "    result = session.run(embedded_text, feed_dict={text_input: text})\n",
    "    import pandas as pd\n",
    "    text_embeddings=pd.DataFrame(result)\n",
    "    return(text_embeddings)\n",
    "doc_embed=get_embeddings(embedded_text,session,test)\n",
    "# doc_embed.to_pickle('doc_embed_us3.pkl')\n",
    "\n",
    "def get_similiarity(target_text_embed,text_to_compare_embed):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similiarity=cosine_similarity(target_text_embed,text_to_compare_embed)\n",
    "    similiarity=pd.DataFrame(similiarity)\n",
    "    return similiarity\n",
    "sim=get_similiarity(doc_embed,doc_embed)\n",
    "np.fill_diagonal(sim.values, 0)\n",
    "# idx=sim.idxmax(axis=1).values[0]\n",
    "# sim[idx]\n",
    "\n",
    "sim.index=test\n",
    "sim.columns=test\n",
    "y=sim.idxmax(axis=1).values.tolist()\n",
    "x=test\n",
    "z=sim.max(axis=1).values.tolist()\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_finetuned=pd.DataFrame([x,y,z]).T\n",
    "# data.to_csv('u3_u4.csv')\n",
    "data_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without finetuning we expect the related technologies should be far,reflecting global or random vector assignment for Out of Vocabulary using Hash Tables\n",
      "uni_sent_module_path https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>nodejs</td>\n",
       "      <td>0.0677032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hive</td>\n",
       "      <td>net</td>\n",
       "      <td>0.154901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asp</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.266492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net</td>\n",
       "      <td>hive</td>\n",
       "      <td>0.154901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>js</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.403418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>javascript</td>\n",
       "      <td>js</td>\n",
       "      <td>0.403418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nodejs</td>\n",
       "      <td>js</td>\n",
       "      <td>0.141451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2\n",
       "0  hadoop      nodejs      0.0677032\n",
       "1  hive        net         0.154901 \n",
       "2  asp         javascript  0.266492 \n",
       "3  net         hive        0.154901 \n",
       "4  js          javascript  0.403418 \n",
       "5  javascript  js          0.403418 \n",
       "6  nodejs      js          0.141451 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Without finetuning we expect the related technologies should be far,reflecting global or random vector assignment for Out of Vocabulary using Hash Tables\")\n",
    "\n",
    "\n",
    "# %%time\n",
    "# #https://github.com/tensorflow/hub/blob/master/docs/common_issues.md#running-inference-on-a-pre-initialized-module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "test=pd.read_excel('test.xlsx')\n",
    "test=test['Curated Risks'].values.tolist()\n",
    "test=[\"hadoop\",\"hive\", \"asp\", \"net\",\"js\",\"javascript\",\"nodejs\"]\n",
    "\n",
    "uni_sent_module_path=\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
    "print ('uni_sent_module_path',uni_sent_module_path)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Create graph and finalize (finalizing optional but recommended).\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  # We will be feeding 1D tensors of text into the graph.\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  #nnlm-en-dim128,universal_sentence_encoder_large_3\n",
    "  embed = hub.Module(uni_sent_module_path,trainable=True)\n",
    "  embedded_text = embed(text_input)\n",
    "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "# Create session and initialize.\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_op)\n",
    "def get_embeddings(embedded_text,session,text):\n",
    "    result = session.run(embedded_text, feed_dict={text_input: text})\n",
    "    import pandas as pd\n",
    "    text_embeddings=pd.DataFrame(result)\n",
    "    return(text_embeddings)\n",
    "doc_embed=get_embeddings(embedded_text,session,test)\n",
    "# doc_embed.to_pickle('doc_embed_us3.pkl')\n",
    "\n",
    "def get_similiarity(target_text_embed,text_to_compare_embed):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similiarity=cosine_similarity(target_text_embed,text_to_compare_embed)\n",
    "    similiarity=pd.DataFrame(similiarity)\n",
    "    return similiarity\n",
    "sim=get_similiarity(doc_embed,doc_embed)\n",
    "np.fill_diagonal(sim.values, 0)\n",
    "# idx=sim.idxmax(axis=1).values[0]\n",
    "# sim[idx]\n",
    "\n",
    "sim.index=test\n",
    "sim.columns=test\n",
    "y=sim.idxmax(axis=1).values.tolist()\n",
    "x=test\n",
    "z=sim.max(axis=1).values.tolist()\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_global=pd.DataFrame([x,y,z]).T\n",
    "# data.to_csv('u3_u4.csv')\n",
    "data_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Global most similiar</th>\n",
       "      <th>Global similiarity</th>\n",
       "      <th>Fine tuned most similiar</th>\n",
       "      <th>Finetuned_similiarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hadoop</td>\n",
       "      <td>nodejs</td>\n",
       "      <td>0.0677032</td>\n",
       "      <td>hive</td>\n",
       "      <td>0.449132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hive</td>\n",
       "      <td>net</td>\n",
       "      <td>0.154901</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>0.449132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asp</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.266492</td>\n",
       "      <td>net</td>\n",
       "      <td>0.481343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net</td>\n",
       "      <td>hive</td>\n",
       "      <td>0.154901</td>\n",
       "      <td>asp</td>\n",
       "      <td>0.481343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>js</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.403418</td>\n",
       "      <td>javascript</td>\n",
       "      <td>0.673985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>javascript</td>\n",
       "      <td>js</td>\n",
       "      <td>0.403418</td>\n",
       "      <td>js</td>\n",
       "      <td>0.673985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nodejs</td>\n",
       "      <td>js</td>\n",
       "      <td>0.141451</td>\n",
       "      <td>js</td>\n",
       "      <td>0.517689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word Global most similiar Global similiarity  \\\n",
       "0  hadoop      nodejs               0.0677032           \n",
       "1  hive        net                  0.154901            \n",
       "2  asp         javascript           0.266492            \n",
       "3  net         hive                 0.154901            \n",
       "4  js          javascript           0.403418            \n",
       "5  javascript  js                   0.403418            \n",
       "6  nodejs      js                   0.141451            \n",
       "\n",
       "  Fine tuned most similiar Finetuned_similiarity  \n",
       "0  hive                     0.449132              \n",
       "1  hadoop                   0.449132              \n",
       "2  net                      0.481343              \n",
       "3  asp                      0.481343              \n",
       "4  javascript               0.673985              \n",
       "5  js                       0.673985              \n",
       "6  js                       0.517689              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finetuned.columns=['word','Fine tuned most similiar','Finetuned_similiarity']\n",
    "data_global.columns=['word','Global most similiar','Global similiarity']\n",
    "data_global.merge(data_finetuned,how='left',on='word')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python]",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
