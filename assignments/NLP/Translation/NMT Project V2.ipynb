{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation from Hindi to English\n",
    "\n",
    "\n",
    "Assignment is to build a Neural Machine Translation (NMT) model to translate Hindi Sentences into machine English. \n",
    "\n",
    "We will do this using by creating attention model as in Neural Machine Translation by Jointly Learning to Align and Translate: Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio https://arxiv.org/pdf/1409.0473.pdf\n",
    "\n",
    "We will be using following small parallel corpus \"http://www.manythings.org/anki/hin-eng.zip\"\n",
    "\n",
    "Notes: In Appendix section at end we have given additional helper functions which can be used to improve model as future improvement effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "#nmt utils has functions which will be used for Softmax or Data Procesing.\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Translating human readable dates into machine readable dates\n",
    "\n",
    "The model we will build here could be used to translate from from English to Hindi or any other parallel corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset\n",
    "\n",
    "In this section we are going to download the dataset and prepare the dataset with Padding & Integer Encoding & One hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hin.txt exists\n"
     ]
    }
   ],
   "source": [
    "import requests, zipfile, io,os\n",
    "r = requests.get(\"http://www.manythings.org/anki/hin-eng.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "#Verifying if the file hin.txt are downloaded properly.\n",
    "if os.path.isfile(\"hin.txt\"):\n",
    "    print('hin.txt exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file\n",
    "file=open(\"hin.txt\",'r',encoding='utf-8')\n",
    "content=file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean pairs 2867\n",
      "Saved: english-hindi.pkl\n",
      "[Help] => [बचाओ]\n",
      "[Jump] => [उछलो]\n",
      "[Jump] => [कूदो]\n",
      "[Jump] => [छलांग]\n",
      "[Hello] => [नमस्ते]\n",
      "[Hello] => [नमस्कार]\n",
      "[Cheers] => [वाहवाह]\n",
      "[Cheers] => [चियर्स]\n",
      "[Got it] => [समझे कि नहीं]\n",
      "[Im OK] => [मैं ठीक हूँ]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "\tlines = doc.strip().split('\\n')\n",
    "\tpairs = [line.split('\\t') for line in  lines]\n",
    "\treturn pairs\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_punc = re.compile('[।%s]' % re.escape(string.punctuation))\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\tfor pair in lines:\n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "\t\t\t# tokenize on white space\n",
    "\t\t\tline = line.split()\n",
    "\t\t\t# remove punctuation from each token\n",
    "\t\t\tline = [re_punc.sub('', w) for w in line]\n",
    "\t\t\t# remove tokens with numbers in them\n",
    "\t\t\t#line = [word for word in line if word.isalpha()]\n",
    "\t\t\t#line=re.sub('[।]', '', line)\n",
    "\t\t\t# store as string\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "filename = 'hin.txt'\n",
    "doc = load_doc(filename)\n",
    "# split into english-hindi pairs\n",
    "pairs = to_pairs(doc)\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "# save clean pairs to file\n",
    "print (\"Number of clean pairs\",clean_pairs.shape[0])\n",
    "save_clean_data(clean_pairs, 'english-hindi.pkl')\n",
    "# spot check\n",
    "for i in range(10):\n",
    "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867\n",
      "Saved: english-hindi-both.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "# load dataset\n",
    "raw_dataset = load_clean_sentences('english-hindi.pkl')\n",
    "\n",
    "# reduce dataset size\n",
    "n_sentences = raw_dataset.shape[0]\n",
    "print (n_sentences)\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test\n",
    "train, test = dataset[:2800], dataset[2800:]\n",
    "# save\n",
    "save_clean_data(dataset, 'english-hindi-both.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2867, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the data sample\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting it to tuples.\n",
    "dataset_list=(list(tuple(map(tuple, dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English Sentence List\n",
    "english_sentences_list=list(dataset[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please make yourself at home'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences_list[0]='Please make yourself at home'\n",
    "english_sentences_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English Sentence Unique Word List and Length of Vocabulary\n",
    "english_unique_words=set((' '.join(english_sentences_list)).split())\n",
    "english_vocab_len=len(set((' '.join(english_sentences_list)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hindi Sentence List\n",
    "hindi_sentences_list=list(dataset[:,1])\n",
    "hindi_sentences_list[0]='इसको अपना घर ही समझो'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hindi Sentence Unique Word List and Length of Vocabulary\n",
    "hindi_unique_words=set((' '.join(hindi_sentences_list)).split())\n",
    "hindi_vocab_len=len(set((' '.join(hindi_sentences_list)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dictionary with Unknown and Pad elements\n",
    "english_dictionary=dict(zip(sorted(english_unique_words) + ['<unk>', '<pad>'], list(range(len(english_unique_words) + 2))))\n",
    "hindi_dictionary=dict(zip(sorted(hindi_unique_words) + ['<unk>', '<pad>'], list(range(len(hindi_unique_words) + 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse Dictionary for both languages\n",
    "revere_dictionary_hindi=dict((v,k) for k,v in hindi_dictionary.items())\n",
    "revere_dictionary_english=dict((v,k) for k,v in english_dictionary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the index of padding value in variables to add it going ahead.\n",
    "english_padding_value=english_dictionary['<pad>']\n",
    "hindi_padding_value=hindi_dictionary['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 25\n"
     ]
    }
   ],
   "source": [
    "#This going to be the global variable with maximum number of words found in a sentence\n",
    "max_english_words=max(len(line.split()) for line in english_sentences_list)\n",
    "max_hindi_words=max(len(line.split()) for line in hindi_sentences_list)\n",
    "print(max_english_words,max_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_encoding(sentences_list,language_dictionary,max_language_words):\n",
    "    padding_value=language_dictionary['<pad>']\n",
    "    language_array=[]\n",
    "    #Iterate over List.\n",
    "    for sentence in sentences_list:\n",
    "        #Replaces English words with English Vocabulary Indexes and Hindi with Hindi Vocabulary Indexes.\n",
    "        #logic: if a word not in dictionary enters, it will be replaced by unk key value.\n",
    "        single_sentence_array=[]\n",
    "        for word in sentence.split(): \n",
    "            try:\n",
    "                #single_sentence_array=([language_dictionary[word] for word in sentence.split()])\n",
    "                single_sentence_array.append(language_dictionary[word])\n",
    "            except KeyError:\n",
    "                unk='<unk>'\n",
    "                single_sentence_array.append(language_dictionary[unk])\n",
    "        #Find the length of english_single_sentence_array\n",
    "        length_single_sentence=(len(single_sentence_array))\n",
    "        #So how many times padding dictionary key needs to be appended, if we say maximum length of sentences to be considered is eng_max_len.\n",
    "        if (max_language_words>length_single_sentence):\n",
    "            padding_count=(max_language_words-length_single_sentence)\n",
    "        else:\n",
    "            padding_count=0\n",
    "        if (padding_count>0):\n",
    "            for pad in range(0,padding_count):\n",
    "                single_sentence_array.append(padding_value)\n",
    "        else:\n",
    "            single_sentence_array=single_sentence_array[0:max_language_words]\n",
    "        #Append to main array\n",
    "        language_array.append(single_sentence_array)\n",
    "    #Convert to Numpy array at the end\n",
    "    language_array=np.array(language_array)\n",
    "    return(language_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing a padding over large sentence size, emperically it is found that it is better to do for a short sentences considering the limitation we are having with respect to corpus size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2867, 6) (2867, 6)\n"
     ]
    }
   ],
   "source": [
    "#Get encoded sentences\n",
    "hindi_encoding=get_padded_encoding(hindi_sentences_list,hindi_dictionary,sentence_length)\n",
    "english_encoding=get_padded_encoding(english_sentences_list,english_dictionary,sentence_length)\n",
    "print(hindi_encoding.shape,english_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am tired of my work मैं अपने काम से थक चुका हूँ\n",
      "[ 185  487 2377 1711 1646 2580] [2189   61  468 2707 1221  852]\n",
      "I\n",
      "am\n",
      "tired\n",
      "of\n",
      "my\n",
      "work\n",
      "मैं\n",
      "अपने\n",
      "काम\n",
      "से\n",
      "थक\n",
      "चुका\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2872"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying the encoding and decoding for a sample data.\n",
    "print(english_sentences_list[1],hindi_sentences_list[1])\n",
    "print(english_encoding[1],hindi_encoding[1])\n",
    "#Check if encoding gives back the same answer\n",
    "for key in english_encoding[1]:\n",
    "    print(revere_dictionary_english[key])\n",
    "for key in hindi_encoding[1]:\n",
    "    print(revere_dictionary_hindi[key])\n",
    "english_dictionary['<pad>']\n",
    "hindi_dictionary['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2867, 6)\n",
      "Y.shape: (2867, 6)\n",
      "Xoh.shape: (2867, 6, 2873)\n",
      "Yoh.shape: (2867, 6, 2620)\n"
     ]
    }
   ],
   "source": [
    "#We will convert the english and hindi encodings to one hot encodings.\n",
    "#Please note Input is of the dimension (number of sentences,max_length_language(every column is a word))\n",
    "#Output is (number of sentences,Max_length_language(every row is a word),length of vocabulary)\n",
    "#Basically every row of the onehotcode matrix must be for one word.\n",
    "#How=1 => 1 0 0\n",
    "#Are=2 => 0 1 0\n",
    "#You=3 => 0 0 1\n",
    "#We are trying to translate hindi to english, so our X is Hindi and Y is English\n",
    "X=hindi_encoding\n",
    "Y=english_encoding\n",
    "#Note: Instead of one hot we can use word embeddings for Xoh\n",
    "Xoh=np.array(list(map(lambda x: to_categorical(x, num_classes=len(hindi_dictionary)), X)))\n",
    "Yoh=np.array(list(map(lambda x: to_categorical(x, num_classes=len(english_dictionary)), Y)))\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tx = hindi_encoding.shape[1]\n",
    "Ty = english_encoding.shape[1]\n",
    "Tx,Ty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You we have:\n",
    "- `X`: a processed version of the hindi in the data set, where each character is replaced by an index mapped to the character via `hindi_vocab`. Each date is further padded to $T_x$ values with a special character (< pad >). `X.shape = (m, Tx)`\n",
    "- `Y`: a processed version of the english sentences in the data set, where each character is replaced by the index it is mapped to in `english_vocab`. You should have `Y.shape = (m, Ty)`. \n",
    "- `Xoh`: one-hot version of `X`, the \"1\" entry's index is mapped to the character thanks to `hindi_vocab`. `Xoh.shape = (m, Tx, len(hindi_vocab))`\n",
    "- `Yoh`: one-hot version of `Y`, the \"1\" entry's index is mapped to the character thanks to `machine_vocab`. `Yoh.shape = (m, Tx, len(english_vocab))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also look at some examples of preprocessed training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: वह हमेशा मन लगाकर काम करती है\n",
      "Target: She always works hard\n",
      "\n",
      "Source after preprocessing (indices): [ 218   59  752 2819 2579 2872]\n",
      "Target after preprocessing (indices): [ 273 1565 2615  550 1345 2619]\n",
      "\n",
      "Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Target after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "#The dataset is english -> Hindi\n",
    "#Our target is to generate English given Hindi\n",
    "print(\"Source:\", dataset_list[index][1])\n",
    "print(\"Target:\", dataset_list[index][0])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural machine translation with attention\n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "\n",
    "### 2.1 - Attention mechanism\n",
    "\n",
    "In this part, we will implement the attention mechanism. The diagram on the left shows the attention model. The diagram on the right shows what one \"Attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$, which are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). One change that we have in our implementation compared to diagram below here is the Post Attention LSTM will be feeding the previous predicted output also by utilizing return_sequences=True feature of Keras.\n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is the summary of model: \n",
    "\n",
    "- There are two separate LSTMs in this model (see diagram on the left). Because the one at the bottom of the picture is a Bi-directional LSTM and comes *before* the attention mechanism, we will call it *pre-attention* Bi-LSTM. The LSTM at the top of the diagram comes *after* the attention mechanism, so we will call it the *post-attention* LSTM. The pre-attention Bi-LSTM goes through $T_x$ time steps; the post-attention LSTM goes through $T_y$ time steps. \n",
    "\n",
    "- The post-attention LSTM passes $s^{\\langle t \\rangle}, c^{\\langle t \\rangle}$ from one time step to the next. We are using an LSTM here, the LSTM has both the output activation $s^{\\langle t\\rangle}$ and the hidden cell state $c^{\\langle t\\rangle}$. \n",
    "\n",
    "- We use $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}; \\overleftarrow{a}^{\\langle t \\rangle}]$ to represent the concatenation of the activations of both the forward-direction and backward-directions of the pre-attention Bi-LSTM. \n",
    "\n",
    "- The diagram on the right uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times, and then `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ to compute $e^{\\langle t, t'}$, which is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$. We'll explain how to use `RepeatVector` and `Concatenation` in Keras below. \n",
    "\n",
    "Implementation detail of the model. \n",
    "\n",
    "We will start by implementing two functions: `one_step_attention()` and `model()`.\n",
    "\n",
    "**1) `one_step_attention()`**: At step $t$, given all the hidden states of the Bi-LSTM ($[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$) and the previous hidden state of the second LSTM ($s^{<t-1>}$), `one_step_attention()` will compute the attention weights ($[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$) and output the context vector (see Figure  1 (right) for details):\n",
    "$$context^{<t>} = \\sum_{t' = 0}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "Note that we are denoting the attention in this notebook $context^{\\langle t \\rangle}$. In the lecture videos, the context was denoted $c^{\\langle t \\rangle}$, but here we are calling it $context^{\\langle t \\rangle}$ to avoid confusion with the (post-attention) LSTM's internal memory cell variable, which is sometimes also denoted $c^{\\langle t \\rangle}$. \n",
    "  \n",
    "**2) `model()`**: Implements the entire model. It first runs the input through a Bi-LSTM to get back $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. Then, it calls `one_step_attention()` $T_y$ times (`for` loop). At each iteration of this loop, it gives the computed context vector $c^{<t>}$ to the second LSTM, and runs the output of the LSTM through a dense layer with softmax activation to generate a prediction $\\hat{y}^{<t>}$. \n",
    "\n",
    "\n",
    "\n",
    "Implementation of `one_step_attention()`. The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop, and it is important that all $T_y$ copies have the same weights. I.e., it should not re-initiaiize the weights every time. In other words, all $T_y$ steps should have shared weights. Here's how we implement layers with shareable weights in Keras:\n",
    "1. Define the layer objects (as global variables for examples).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "We have defined the layers we need as global variables. Please run the following cells to create them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor = Dense(1,activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') \n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these layers to implement `one_step_attention()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" \n",
    "    print (\"s_prev.shape before repeator\",s_prev.shape)\n",
    "    s_prev = repeator(s_prev)\n",
    "    print (\"s_prev.shape after repeator\",s_prev.shape)\n",
    "    print (\"a.shape\",a.shape)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis \n",
    "    concat = concatenator([a, s_prev])\n",
    "    print (\"concat.shape\",concat.shape)\n",
    "    # Use densor to propagate concat through a small fully-connected neural network to compute the \"energies\" variable e.\n",
    "    e = densor(concat)\n",
    "    print (\"e.shape\",e.shape)\n",
    "    # Use activator and e to compute the attention weights \"alphas\" \n",
    "    alphas = activator(e)\n",
    "    print (\"alphas.shape\",alphas.shape)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell\n",
    "    context = dotor([alphas, a])\n",
    "    print (\"context.shape\",context.shape)\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined global layers that will share weights to be used in `model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_a and n_s are the LSTM internal states. Can be selected arbitarily.\n",
    "n_a = 500\n",
    "n_s = 500\n",
    "#We have added dropout to avoid overfiting\n",
    "post_activation_LSTM_cell = (LSTM(n_s, activation='relu',return_sequences=True,return_state = True,dropout=0.4))\n",
    "output_layer = Dense(len(english_dictionary), activation=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these layers $T_y$ times in a `for` loop to generate the outputs, and their parameters will not be reinitialized. We will have to carry out the following steps: \n",
    "\n",
    "1. Propagate the input into a Bidirectional LSTM\n",
    "2. Iterate for $t = 0, \\dots, T_y-1$: \n",
    "    1. Call `one_step_attention()` on $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$ and $s^{<t-1>}$ to get the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell. We will pass in the previous hidden-state $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM using `initial_state= [previous hidden state, previous cell state]`. To predict the next LSTM cell, output are fed again by using return_sequences=True. Get back the new hidden state $s^{<t>}$ and the new cell state $c^{<t>}$.\n",
    "    3. Apply a softmax layer to $s^{<t>}$, get the output. \n",
    "    4. Save the output by adding it to the list of outputs.\n",
    "\n",
    "3. Create Keras model instance, it should have three inputs (\"inputs\", $s^{<0>}$ and $c^{<0>}$) and output the list of \"outputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, source_dictionary_size, target_dictionary_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, source_dictionary_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 1: Define pre-attention Bi-LSTM.\n",
    "    a1 = Bidirectional(LSTM(n_a, activation='relu',return_sequences=True,dropout=0.4))(X)\n",
    "    a = Bidirectional(LSTM(n_a, activation='relu',return_sequences=True,dropout=0.4))(a1)\n",
    "    print(a,a.shape)\n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t\n",
    "        print(\"Before getting Context: a.shape,s.shape\",a.shape,s.shape)\n",
    "        context = one_step_attention(a, s)\n",
    "        print(\"context.shape,s.shape,c.shape \",context.shape,s.shape,c.shape)\n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        _,s, c = post_activation_LSTM_cell(context, initial_state = [s,c])\n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM \n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. \n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bidirectional_2/concat_2:0\", shape=(?, ?, 1000), dtype=float32) (?, ?, 1000)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n",
      "Before getting Context: a.shape,s.shape (?, ?, 1000) (?, 500)\n",
      "s_prev.shape before repeator (?, 500)\n",
      "s_prev.shape after repeator (?, 6, 500)\n",
      "a.shape (?, ?, 1000)\n",
      "concat.shape (?, 6, 1500)\n",
      "e.shape (?, 6, 1)\n",
      "alphas.shape (?, 6, 1)\n",
      "context.shape (?, 1, 1000)\n",
      "context.shape,s.shape,c.shape  (?, 1, 1000) (?, 500) (?, 500)\n"
     ]
    }
   ],
   "source": [
    "#We are also printing the shapes, just for the purpose of debug.\n",
    "model = model(Tx, Ty, n_a, n_s, len(hindi_dictionary), len(english_dictionary))\n",
    "\n",
    "#We will need copy of the model which will use the weights from model.fit.\n",
    "#This is done as it is observed there has been issues model.load_weights(weightFile)\n",
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 6, 2873)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 6, 1000)       13496000    input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "s0 (InputLayer)                  (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 6, 1000)       6004000     bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)   (None, 6, 500)        0           s0[0][0]                         \n",
      "                                                                   lstm_1[0][1]                     \n",
      "                                                                   lstm_1[1][1]                     \n",
      "                                                                   lstm_1[2][1]                     \n",
      "                                                                   lstm_1[3][1]                     \n",
      "                                                                   lstm_1[4][1]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 6, 1500)       0           bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[0][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[1][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[2][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[3][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[4][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_1[5][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 6, 1)          1501        concatenate_1[0][0]              \n",
      "                                                                   concatenate_1[1][0]              \n",
      "                                                                   concatenate_1[2][0]              \n",
      "                                                                   concatenate_1[3][0]              \n",
      "                                                                   concatenate_1[4][0]              \n",
      "                                                                   concatenate_1[5][0]              \n",
      "____________________________________________________________________________________________________\n",
      "attention_weights (Activation)   (None, 6, 1)          0           dense_1[0][0]                    \n",
      "                                                                   dense_1[1][0]                    \n",
      "                                                                   dense_1[2][0]                    \n",
      "                                                                   dense_1[3][0]                    \n",
      "                                                                   dense_1[4][0]                    \n",
      "                                                                   dense_1[5][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1, 1000)       0           attention_weights[0][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[1][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[2][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[3][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[4][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[5][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 1, 500), (Non 3002000     dot_1[0][0]                      \n",
      "                                                                   s0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   dot_1[1][0]                      \n",
      "                                                                   lstm_1[0][1]                     \n",
      "                                                                   lstm_1[0][2]                     \n",
      "                                                                   dot_1[2][0]                      \n",
      "                                                                   lstm_1[1][1]                     \n",
      "                                                                   lstm_1[1][2]                     \n",
      "                                                                   dot_1[3][0]                      \n",
      "                                                                   lstm_1[2][1]                     \n",
      "                                                                   lstm_1[2][2]                     \n",
      "                                                                   dot_1[4][0]                      \n",
      "                                                                   lstm_1[3][1]                     \n",
      "                                                                   lstm_1[3][2]                     \n",
      "                                                                   dot_1[5][0]                      \n",
      "                                                                   lstm_1[4][1]                     \n",
      "                                                                   lstm_1[4][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2620)          1312620     lstm_1[0][1]                     \n",
      "                                                                   lstm_1[1][1]                     \n",
      "                                                                   lstm_1[2][1]                     \n",
      "                                                                   lstm_1[3][1]                     \n",
      "                                                                   lstm_1[4][1]                     \n",
      "                                                                   lstm_1[5][1]                     \n",
      "====================================================================================================\n",
      "Total params: 23,816,121\n",
      "Trainable params: 23,816,121\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating your model in Keras, we need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using `categorical_crossentropy` loss, and optimizer rmsprop or Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "out = model.compile(optimizer='rmsprop'#(lr=0.001, beta_1=0.7, beta_2=0.8, decay=0.02)\n",
    "                    ,metrics=['accuracy'],\n",
    "                    loss='categorical_crossentropy')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to define all your inputs and outputs to fit the model:\n",
    "- We already have X of shape $(m ,T_x )$ containing the training examples.\n",
    "- We need to create `s0` and `c0` to initialize your `post_activation_LSTM_cell` with 0s.\n",
    "- Given the `model()` you coded, you need the \"outputs\" to be a list of elements of shape (m, T_y). So that: `outputs[i][0], ..., outputs[i][Ty]` represent the true labels (characters) corresponding to the $i^{th}$ training example (`X[i]`). More generally, `outputs[i][j]` is the true label of the $j^{th}$ character in the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((len(dataset_list), n_s))\n",
    "c0 = np.zeros((len(dataset_list), n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples,Training,Testing 2867 2810 57\n",
      "Training X Shape and Y Shape (2810, 6, 2873) (2810, 6, 2620)\n",
      "Testing X Shape and Y Shape (57, 6, 2873) (57, 6, 2620)\n"
     ]
    }
   ],
   "source": [
    "#Divide data in to train & test\n",
    "#How much percentage of total data you need enter the number for training_sample_percentage\n",
    "training_sample_percentage=98\n",
    "training_sample_count=(round(X.shape[0]*training_sample_percentage/100))\n",
    "#training_sample_count=2\n",
    "#For to cover rest of data\n",
    "testing_sample_count=X.shape[0]-training_sample_count\n",
    "#testing_sample_count\n",
    "testing_sample_index=training_sample_count+testing_sample_count\n",
    "\n",
    "print(\"Total Samples,Training,Testing\",X.shape[0],training_sample_count,testing_sample_count)\n",
    "trainXoh=Xoh[0:training_sample_count]\n",
    "trainYoh=Yoh[0:training_sample_count]\n",
    "testXoh=Xoh[training_sample_count:testing_sample_index]\n",
    "testYoh=Yoh[training_sample_count:testing_sample_index]\n",
    "print(\"Training X Shape and Y Shape\",trainXoh.shape,trainYoh.shape)\n",
    "print(\"Testing X Shape and Y Shape\",testXoh.shape,testYoh.shape)\n",
    "train_outputs = list(trainYoh.swapaxes(0,1))\n",
    "test_outputs = list(testYoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2867, 500) (2867, 500)\n"
     ]
    }
   ],
   "source": [
    "train_s0 = np.zeros((training_sample_count, n_s))\n",
    "train_c0 = np.zeros((training_sample_count, n_s))\n",
    "trainX=[trainXoh, train_s0, train_c0]\n",
    "trainY=train_outputs\n",
    "test_s0 = np.zeros((testing_sample_count, n_s))\n",
    "test_c0 = np.zeros((testing_sample_count, n_s))\n",
    "testX=[testXoh, test_s0, test_c0]\n",
    "testY=test_outputs\n",
    "print(s0.shape,c0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2810 samples, validate on 57 samples\n",
      "Epoch 1/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 31.8713 - dense_2_loss_1: 4.2636 - dense_2_loss_2: 6.0400 - dense_2_loss_3: 5.9195 - dense_2_loss_4: 6.0314 - dense_2_loss_5: 5.3107 - dense_2_loss_6: 4.3060 - dense_2_acc_1: 0.1707 - dense_2_acc_2: 0.0754 - dense_2_acc_3: 0.0600 - dense_2_acc_4: 0.1007 - dense_2_acc_5: 0.2325 - dense_2_acc_6: 0.4171Epoch 00000: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 129s - loss: 31.8792 - dense_2_loss_1: 4.2607 - dense_2_loss_2: 6.0408 - dense_2_loss_3: 5.9215 - dense_2_loss_4: 6.0289 - dense_2_loss_5: 5.3158 - dense_2_loss_6: 4.3115 - dense_2_acc_1: 0.1705 - dense_2_acc_2: 0.0754 - dense_2_acc_3: 0.0601 - dense_2_acc_4: 0.1007 - dense_2_acc_5: 0.2320 - dense_2_acc_6: 0.4167 - val_loss: 33.0448 - val_dense_2_loss_1: 4.3732 - val_dense_2_loss_2: 6.3249 - val_dense_2_loss_3: 6.1032 - val_dense_2_loss_4: 6.3106 - val_dense_2_loss_5: 5.4926 - val_dense_2_loss_6: 4.4403 - val_dense_2_acc_1: 0.1754 - val_dense_2_acc_2: 0.0175 - val_dense_2_acc_3: 0.0702 - val_dense_2_acc_4: 0.1228 - val_dense_2_acc_5: 0.2632 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 2/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 30.8560 - dense_2_loss_1: 4.0229 - dense_2_loss_2: 5.8179 - dense_2_loss_3: 5.7485 - dense_2_loss_4: 5.9012 - dense_2_loss_5: 5.1645 - dense_2_loss_6: 4.2010 - dense_2_acc_1: 0.1732 - dense_2_acc_2: 0.0811 - dense_2_acc_3: 0.0718 - dense_2_acc_4: 0.1129 - dense_2_acc_5: 0.2389 - dense_2_acc_6: 0.4154Epoch 00001: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 128s - loss: 30.8518 - dense_2_loss_1: 4.0209 - dense_2_loss_2: 5.8200 - dense_2_loss_3: 5.7486 - dense_2_loss_4: 5.9022 - dense_2_loss_5: 5.1614 - dense_2_loss_6: 4.1987 - dense_2_acc_1: 0.1730 - dense_2_acc_2: 0.0808 - dense_2_acc_3: 0.0715 - dense_2_acc_4: 0.1132 - dense_2_acc_5: 0.2399 - dense_2_acc_6: 0.4153 - val_loss: 32.4331 - val_dense_2_loss_1: 4.2075 - val_dense_2_loss_2: 6.2643 - val_dense_2_loss_3: 6.0953 - val_dense_2_loss_4: 6.2989 - val_dense_2_loss_5: 5.3763 - val_dense_2_loss_6: 4.1909 - val_dense_2_acc_1: 0.1930 - val_dense_2_acc_2: 0.0175 - val_dense_2_acc_3: 0.0702 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2807 - val_dense_2_acc_6: 0.4386\n",
      "Epoch 3/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 30.0997 - dense_2_loss_1: 3.8674 - dense_2_loss_2: 5.6532 - dense_2_loss_3: 5.6085 - dense_2_loss_4: 5.8112 - dense_2_loss_5: 5.0678 - dense_2_loss_6: 4.0915 - dense_2_acc_1: 0.1979 - dense_2_acc_2: 0.0886 - dense_2_acc_3: 0.0796 - dense_2_acc_4: 0.1146 - dense_2_acc_5: 0.2425 - dense_2_acc_6: 0.4132Epoch 00002: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 129s - loss: 30.0946 - dense_2_loss_1: 3.8704 - dense_2_loss_2: 5.6534 - dense_2_loss_3: 5.6123 - dense_2_loss_4: 5.8076 - dense_2_loss_5: 5.0637 - dense_2_loss_6: 4.0872 - dense_2_acc_1: 0.1979 - dense_2_acc_2: 0.0883 - dense_2_acc_3: 0.0794 - dense_2_acc_4: 0.1149 - dense_2_acc_5: 0.2431 - dense_2_acc_6: 0.4139 - val_loss: 32.3340 - val_dense_2_loss_1: 4.1118 - val_dense_2_loss_2: 6.2205 - val_dense_2_loss_3: 6.1081 - val_dense_2_loss_4: 6.3681 - val_dense_2_loss_5: 5.3867 - val_dense_2_loss_6: 4.1388 - val_dense_2_acc_1: 0.2632 - val_dense_2_acc_2: 0.0175 - val_dense_2_acc_3: 0.0702 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2982 - val_dense_2_acc_6: 0.4386\n",
      "Epoch 4/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 29.4731 - dense_2_loss_1: 3.7810 - dense_2_loss_2: 5.5057 - dense_2_loss_3: 5.4947 - dense_2_loss_4: 5.6942 - dense_2_loss_5: 4.9894 - dense_2_loss_6: 4.0082 - dense_2_acc_1: 0.2264 - dense_2_acc_2: 0.0946 - dense_2_acc_3: 0.0846 - dense_2_acc_4: 0.1239 - dense_2_acc_5: 0.2482 - dense_2_acc_6: 0.4171Epoch 00003: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 129s - loss: 29.4820 - dense_2_loss_1: 3.7825 - dense_2_loss_2: 5.5052 - dense_2_loss_3: 5.4988 - dense_2_loss_4: 5.6969 - dense_2_loss_5: 4.9867 - dense_2_loss_6: 4.0118 - dense_2_acc_1: 0.2263 - dense_2_acc_2: 0.0943 - dense_2_acc_3: 0.0843 - dense_2_acc_4: 0.1235 - dense_2_acc_5: 0.2484 - dense_2_acc_6: 0.4171 - val_loss: 32.0914 - val_dense_2_loss_1: 4.0571 - val_dense_2_loss_2: 6.1320 - val_dense_2_loss_3: 6.0836 - val_dense_2_loss_4: 6.2601 - val_dense_2_loss_5: 5.4447 - val_dense_2_loss_6: 4.1139 - val_dense_2_acc_1: 0.2281 - val_dense_2_acc_2: 0.0175 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2807 - val_dense_2_acc_6: 0.4386\n",
      "Epoch 5/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 28.9500 - dense_2_loss_1: 3.6531 - dense_2_loss_2: 5.3845 - dense_2_loss_3: 5.4286 - dense_2_loss_4: 5.6235 - dense_2_loss_5: 4.9273 - dense_2_loss_6: 3.9331 - dense_2_acc_1: 0.2389 - dense_2_acc_2: 0.1075 - dense_2_acc_3: 0.0907 - dense_2_acc_4: 0.1218 - dense_2_acc_5: 0.2500 - dense_2_acc_6: 0.4196Epoch 00004: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 130s - loss: 28.9523 - dense_2_loss_1: 3.6566 - dense_2_loss_2: 5.3838 - dense_2_loss_3: 5.4287 - dense_2_loss_4: 5.6223 - dense_2_loss_5: 4.9300 - dense_2_loss_6: 3.9310 - dense_2_acc_1: 0.2384 - dense_2_acc_2: 0.1078 - dense_2_acc_3: 0.0907 - dense_2_acc_4: 0.1224 - dense_2_acc_5: 0.2498 - dense_2_acc_6: 0.4196 - val_loss: 31.9477 - val_dense_2_loss_1: 3.9856 - val_dense_2_loss_2: 6.0787 - val_dense_2_loss_3: 6.0982 - val_dense_2_loss_4: 6.2858 - val_dense_2_loss_5: 5.3995 - val_dense_2_loss_6: 4.1000 - val_dense_2_acc_1: 0.2807 - val_dense_2_acc_2: 0.0351 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2807 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 6/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 28.4327 - dense_2_loss_1: 3.5639 - dense_2_loss_2: 5.2713 - dense_2_loss_3: 5.3363 - dense_2_loss_4: 5.5315 - dense_2_loss_5: 4.8684 - dense_2_loss_6: 3.8614 - dense_2_acc_1: 0.2675 - dense_2_acc_2: 0.1254 - dense_2_acc_3: 0.0989 - dense_2_acc_4: 0.1254 - dense_2_acc_5: 0.2482 - dense_2_acc_6: 0.4179Epoch 00005: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 131s - loss: 28.4297 - dense_2_loss_1: 3.5598 - dense_2_loss_2: 5.2699 - dense_2_loss_3: 5.3353 - dense_2_loss_4: 5.5317 - dense_2_loss_5: 4.8693 - dense_2_loss_6: 3.8638 - dense_2_acc_1: 0.2683 - dense_2_acc_2: 0.1260 - dense_2_acc_3: 0.0986 - dense_2_acc_4: 0.1253 - dense_2_acc_5: 0.2480 - dense_2_acc_6: 0.4178 - val_loss: 31.6382 - val_dense_2_loss_1: 3.9089 - val_dense_2_loss_2: 6.0711 - val_dense_2_loss_3: 6.0431 - val_dense_2_loss_4: 6.1916 - val_dense_2_loss_5: 5.3166 - val_dense_2_loss_6: 4.1069 - val_dense_2_acc_1: 0.2281 - val_dense_2_acc_2: 0.0526 - val_dense_2_acc_3: 0.0526 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2982 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 7/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 27.9510 - dense_2_loss_1: 3.4307 - dense_2_loss_2: 5.1917 - dense_2_loss_3: 5.2602 - dense_2_loss_4: 5.4508 - dense_2_loss_5: 4.7971 - dense_2_loss_6: 3.8206 - dense_2_acc_1: 0.2889 - dense_2_acc_2: 0.1250 - dense_2_acc_3: 0.1057 - dense_2_acc_4: 0.1236 - dense_2_acc_5: 0.2532 - dense_2_acc_6: 0.4225Epoch 00006: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 131s - loss: 27.9502 - dense_2_loss_1: 3.4288 - dense_2_loss_2: 5.1916 - dense_2_loss_3: 5.2585 - dense_2_loss_4: 5.4510 - dense_2_loss_5: 4.8003 - dense_2_loss_6: 3.8200 - dense_2_acc_1: 0.2897 - dense_2_acc_2: 0.1246 - dense_2_acc_3: 0.1064 - dense_2_acc_4: 0.1238 - dense_2_acc_5: 0.2530 - dense_2_acc_6: 0.4224 - val_loss: 31.5276 - val_dense_2_loss_1: 3.7740 - val_dense_2_loss_2: 6.0149 - val_dense_2_loss_3: 5.9807 - val_dense_2_loss_4: 6.1658 - val_dense_2_loss_5: 5.4419 - val_dense_2_loss_6: 4.1504 - val_dense_2_acc_1: 0.2456 - val_dense_2_acc_2: 0.0702 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.2982 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 8/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 27.5217 - dense_2_loss_1: 3.3192 - dense_2_loss_2: 5.0972 - dense_2_loss_3: 5.1862 - dense_2_loss_4: 5.3971 - dense_2_loss_5: 4.7398 - dense_2_loss_6: 3.7823 - dense_2_acc_1: 0.3093 - dense_2_acc_2: 0.1364 - dense_2_acc_3: 0.1146 - dense_2_acc_4: 0.1282 - dense_2_acc_5: 0.2532 - dense_2_acc_6: 0.4239Epoch 00007: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 130s - loss: 27.5152 - dense_2_loss_1: 3.3164 - dense_2_loss_2: 5.0989 - dense_2_loss_3: 5.1826 - dense_2_loss_4: 5.3984 - dense_2_loss_5: 4.7396 - dense_2_loss_6: 3.7793 - dense_2_acc_1: 0.3093 - dense_2_acc_2: 0.1367 - dense_2_acc_3: 0.1146 - dense_2_acc_4: 0.1285 - dense_2_acc_5: 0.2534 - dense_2_acc_6: 0.4238 - val_loss: 31.5022 - val_dense_2_loss_1: 3.7620 - val_dense_2_loss_2: 6.0223 - val_dense_2_loss_3: 5.9773 - val_dense_2_loss_4: 6.2698 - val_dense_2_loss_5: 5.3163 - val_dense_2_loss_6: 4.1544 - val_dense_2_acc_1: 0.2807 - val_dense_2_acc_2: 0.0526 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1579 - val_dense_2_acc_5: 0.3158 - val_dense_2_acc_6: 0.4386\n",
      "Epoch 9/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 27.1548 - dense_2_loss_1: 3.2638 - dense_2_loss_2: 5.0430 - dense_2_loss_3: 5.1210 - dense_2_loss_4: 5.3285 - dense_2_loss_5: 4.6759 - dense_2_loss_6: 3.7226 - dense_2_acc_1: 0.3079 - dense_2_acc_2: 0.1332 - dense_2_acc_3: 0.1171 - dense_2_acc_4: 0.1275 - dense_2_acc_5: 0.2604 - dense_2_acc_6: 0.4250Epoch 00008: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 130s - loss: 27.1659 - dense_2_loss_1: 3.2618 - dense_2_loss_2: 5.0408 - dense_2_loss_3: 5.1259 - dense_2_loss_4: 5.3275 - dense_2_loss_5: 4.6820 - dense_2_loss_6: 3.7278 - dense_2_acc_1: 0.3089 - dense_2_acc_2: 0.1335 - dense_2_acc_3: 0.1167 - dense_2_acc_4: 0.1270 - dense_2_acc_5: 0.2598 - dense_2_acc_6: 0.4246 - val_loss: 32.5624 - val_dense_2_loss_1: 3.7386 - val_dense_2_loss_2: 6.1280 - val_dense_2_loss_3: 6.0471 - val_dense_2_loss_4: 6.3661 - val_dense_2_loss_5: 5.9094 - val_dense_2_loss_6: 4.3731 - val_dense_2_acc_1: 0.2982 - val_dense_2_acc_2: 0.0702 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1228 - val_dense_2_acc_5: 0.2632 - val_dense_2_acc_6: 0.4035\n",
      "Epoch 10/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 26.7600 - dense_2_loss_1: 3.1874 - dense_2_loss_2: 4.9595 - dense_2_loss_3: 5.0455 - dense_2_loss_4: 5.2517 - dense_2_loss_5: 4.6285 - dense_2_loss_6: 3.6875 - dense_2_acc_1: 0.3221 - dense_2_acc_2: 0.1429 - dense_2_acc_3: 0.1196 - dense_2_acc_4: 0.1375 - dense_2_acc_5: 0.2636 - dense_2_acc_6: 0.4207Epoch 00009: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 130s - loss: 26.7643 - dense_2_loss_1: 3.1880 - dense_2_loss_2: 4.9603 - dense_2_loss_3: 5.0461 - dense_2_loss_4: 5.2531 - dense_2_loss_5: 4.6306 - dense_2_loss_6: 3.6862 - dense_2_acc_1: 0.3224 - dense_2_acc_2: 0.1423 - dense_2_acc_3: 0.1196 - dense_2_acc_4: 0.1370 - dense_2_acc_5: 0.2633 - dense_2_acc_6: 0.4210 - val_loss: 31.5204 - val_dense_2_loss_1: 3.6525 - val_dense_2_loss_2: 5.9979 - val_dense_2_loss_3: 5.9415 - val_dense_2_loss_4: 6.2463 - val_dense_2_loss_5: 5.5348 - val_dense_2_loss_6: 4.1474 - val_dense_2_acc_1: 0.2807 - val_dense_2_acc_2: 0.0702 - val_dense_2_acc_3: 0.0877 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.3158 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 11/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 26.4697 - dense_2_loss_1: 3.1378 - dense_2_loss_2: 4.8929 - dense_2_loss_3: 4.9966 - dense_2_loss_4: 5.2142 - dense_2_loss_5: 4.5832 - dense_2_loss_6: 3.6450 - dense_2_acc_1: 0.3207 - dense_2_acc_2: 0.1414 - dense_2_acc_3: 0.1268 - dense_2_acc_4: 0.1361 - dense_2_acc_5: 0.2604 - dense_2_acc_6: 0.4286Epoch 00010: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 129s - loss: 26.4692 - dense_2_loss_1: 3.1359 - dense_2_loss_2: 4.8917 - dense_2_loss_3: 4.9970 - dense_2_loss_4: 5.2142 - dense_2_loss_5: 4.5844 - dense_2_loss_6: 3.6459 - dense_2_acc_1: 0.3206 - dense_2_acc_2: 0.1420 - dense_2_acc_3: 0.1263 - dense_2_acc_4: 0.1359 - dense_2_acc_5: 0.2598 - dense_2_acc_6: 0.4285 - val_loss: 31.4509 - val_dense_2_loss_1: 3.6290 - val_dense_2_loss_2: 6.1233 - val_dense_2_loss_3: 6.0013 - val_dense_2_loss_4: 6.2014 - val_dense_2_loss_5: 5.4140 - val_dense_2_loss_6: 4.0819 - val_dense_2_acc_1: 0.2982 - val_dense_2_acc_2: 0.0877 - val_dense_2_acc_3: 0.1228 - val_dense_2_acc_4: 0.1579 - val_dense_2_acc_5: 0.3158 - val_dense_2_acc_6: 0.4035\n",
      "Epoch 12/200\n",
      "2800/2810 [============================>.] - ETA: 0s - loss: 26.2531 - dense_2_loss_1: 3.1097 - dense_2_loss_2: 4.8460 - dense_2_loss_3: 4.9484 - dense_2_loss_4: 5.1629 - dense_2_loss_5: 4.5495 - dense_2_loss_6: 3.6366 - dense_2_acc_1: 0.3271 - dense_2_acc_2: 0.1436 - dense_2_acc_3: 0.1246 - dense_2_acc_4: 0.1304 - dense_2_acc_5: 0.2586 - dense_2_acc_6: 0.4254Epoch 00011: saving model to main_model_weights_new.h5\n",
      "2810/2810 [==============================] - 130s - loss: 26.2516 - dense_2_loss_1: 3.1084 - dense_2_loss_2: 4.8457 - dense_2_loss_3: 4.9496 - dense_2_loss_4: 5.1639 - dense_2_loss_5: 4.5488 - dense_2_loss_6: 3.6352 - dense_2_acc_1: 0.3274 - dense_2_acc_2: 0.1434 - dense_2_acc_3: 0.1249 - dense_2_acc_4: 0.1302 - dense_2_acc_5: 0.2587 - dense_2_acc_6: 0.4253 - val_loss: 31.3922 - val_dense_2_loss_1: 3.5752 - val_dense_2_loss_2: 6.0900 - val_dense_2_loss_3: 6.0117 - val_dense_2_loss_4: 6.2329 - val_dense_2_loss_5: 5.4409 - val_dense_2_loss_6: 4.0415 - val_dense_2_acc_1: 0.3333 - val_dense_2_acc_2: 0.0877 - val_dense_2_acc_3: 0.1228 - val_dense_2_acc_4: 0.1404 - val_dense_2_acc_5: 0.3158 - val_dense_2_acc_6: 0.4211\n",
      "Epoch 13/200\n",
      "2320/2810 [=======================>......] - ETA: 22s - loss: 25.7513 - dense_2_loss_1: 3.0465 - dense_2_loss_2: 4.7638 - dense_2_loss_3: 4.8469 - dense_2_loss_4: 5.0572 - dense_2_loss_5: 4.5245 - dense_2_loss_6: 3.5124 - dense_2_acc_1: 0.3397 - dense_2_acc_2: 0.1422 - dense_2_acc_3: 0.1362 - dense_2_acc_4: 0.1388 - dense_2_acc_5: 0.2573 - dense_2_acc_6: 0.4336"
     ]
    }
   ],
   "source": [
    "#Run the model.fit. If only best validation model needs to be saved, then change save_best_only=True in checkpoint.\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('main_model_weights_new.h5', monitor='val_loss', verbose=1, save_best_only=False, mode='auto',save_weights_only=True)\n",
    "model.fit(trainX, trainY, epochs=200, batch_size=20, validation_data=(testX, testY), callbacks=[checkpoint])\n",
    "#Hoping to save model without errors.\n",
    "model.save('main_model.h5')\n",
    "model.save_weights('final_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantitative Analysis\n",
    "While training you can see the loss as well as the accuracy on each of the positions of the output. The output snapshot below gives you an example of what the accuracies could be at 100th iteration in above settings: \n",
    "\n",
    "Epoch 100/100\n",
    "2800/2810 [============================>.] - ETA: 0s - loss: 5.1898 - dense_2_loss_1: 0.7850 - dense_2_loss_2: 0.8572 - dense_2_loss_3: 0.8971 - dense_2_loss_4: 0.8881 - dense_2_loss_5: 0.9539 - dense_2_loss_6: 0.8085 - dense_2_acc_1: 0.7875 - dense_2_acc_2: 0.7571 - dense_2_acc_3: 0.7443 - dense_2_acc_4: 0.7479 - dense_2_acc_5: 0.7379 - dense_2_acc_6: 0.7975Epoch 00099: saving model to main_model_weights.h5\n",
    "2810/2810 [==============================] - 17s - loss: 5.1868 - dense_2_loss_1: 0.7848 - dense_2_loss_2: 0.8570 - dense_2_loss_3: 0.8973 - dense_2_loss_4: 0.8891 - dense_2_loss_5: 0.9526 - dense_2_loss_6: 0.8061 - dense_2_acc_1: 0.7872 - dense_2_acc_2: 0.7569 - dense_2_acc_3: 0.7438 - dense_2_acc_4: 0.7480 - dense_2_acc_5: 0.7384 - dense_2_acc_6: 0.7982 - val_loss: 40.8334 - val_dense_2_loss_1: 4.3684 - val_dense_2_loss_2: 7.5746 - val_dense_2_loss_3: 6.9904 - val_dense_2_loss_4: 8.9484 - val_dense_2_loss_5: 6.6466 - val_dense_2_loss_6: 6.3049 - val_dense_2_acc_1: 0.4561 - val_dense_2_acc_2: 0.2807 - val_dense_2_acc_3: 0.1754 - val_dense_2_acc_4: 0.1579 - val_dense_2_acc_5: 0.2456 - val_dense_2_acc_6: 0.3684\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "<caption><left> Thus at 100-th iteration with unaltered settings above, `dense_2_acc_6: 0.7975` means that you are predicting the 6th word of the output correctly 79% of the time in the current batch of data. Also val_dense_2_acc_6: 0.3684 means the 6th digit prediction accuracy is 36%  </left></caption>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qualitative Analysis\n",
    "\n",
    "Following code will load the saved weights which will be used to do a qualitative analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model.load_weights('main_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the results on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES=hindi_sentences_list[0:1]\n",
    "true_test=\"हमने खरीदी\"\n",
    "EXAMPLES.append(true_test)\n",
    "EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_CODED=get_padded_encoding(EXAMPLES,hindi_dictionary,6)\n",
    "print(EXAMPLES_CODED,EXAMPLES_CODED.shape,hindi_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for example in EXAMPLES_CODED:\n",
    "    iteration=i+1\n",
    "    source = example\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(hindi_dictionary)), source))).swapaxes(0,1)\n",
    "    prediction = model.predict([source,train_s0, train_c0])\n",
    "    #print (\"Prediction, Type & Shape:\",prediction,type(prediction),len(prediction))\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    #print (\"Prediction, After Argmax:\",prediction)\n",
    "    output = [revere_dictionary_english[int(i)] for i in prediction]\n",
    "    print(\"\\n ##### \\n\")\n",
    "    print(\"Hindi\",EXAMPLES[i])\n",
    "    if (iteration!=EXAMPLES_CODED.shape[0]):\n",
    "        print(\"Expected:\",english_sentences_list[i])\n",
    "    print(\"Predicted output:\", ' '.join(output))\n",
    "    #print (\"Prediction:\",list(prediction))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to see following results. We have first sentence from training example and another one from true test. We can see that there is a pretty good translation for the data from training and for true test it was able to predict first place pretty accurately but failed in following portions.\n",
    "\n",
    " ##### \n",
    "\n",
    "Hindi इसको अपना घर ही समझो\n",
    "Expected: Please make yourself at home\n",
    "Predicted output: Please yourself yourself home <pad> <pad>\n",
    "\n",
    " ##### \n",
    "\n",
    "Hindi हमने खरीदी\n",
    "Predicted output: We leave up <pad> <pad> <pad>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Machine Translation by Jointly Learning to Align and Translate: Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio https://arxiv.org/pdf/1409.0473.pdf\n",
    "\n",
    "https://machinelearningmastery.com\n",
    "\n",
    "https://www.coursera.org/\n",
    "\n",
    "https://www.udemy.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can do to improve the model is instead of one hot encodings of words of length vocabulary, get the word2vec vectors for each word with fixed length.\n",
    "\n",
    "Another thing that can be done is train only short sentences.\n",
    "\n",
    "In below section we will provide the functions to help to do the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting input to word2vec.\n",
    "def sentences_to_word2vec_input_format(language_sentences_list):\n",
    "    word2vec_sentence_feed=list()\n",
    "    for sentence in language_sentences_list:\n",
    "        word2vec_sentence_feed.append(sentence.split())\n",
    "    return(word2vec_sentence_feed)\n",
    "english_sentences_w2v_format=sentences_to_word2vec_input_format(english_sentences_list)\n",
    "hindi_sentences_w2v_format=sentences_to_word2vec_input_format(hindi_sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# train model\n",
    "english_model = Word2Vec(english_sentences_w2v_format, min_count=1)\n",
    "english_words_vocab = list(english_model.wv.vocab)\n",
    "hindi_model = Word2Vec(hindi_sentences_w2v_format, min_count=1)\n",
    "english_words_vocab = list(hindi_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_w2vec(language_encoding,revere_dictionary_language,language_model):\n",
    "    import numpy as np\n",
    "    sentence_level_w2vec_list=[]\n",
    "    #arr = np.empty((2,), float)\n",
    "    number_of_sentences=language_encoding.shape[0]\n",
    "    for i in range(0,number_of_sentences):\n",
    "        language_list_padded=[]\n",
    "        #print (english_encoding[i])\n",
    "        for key in language_encoding[i]:\n",
    "            #print(revere_dictionary_english[key])\n",
    "            word=(revere_dictionary_language[key])\n",
    "            try:\n",
    "                #print(\"Found word Shape of word vector\",(english_model[word]).shape,arr.shape)\n",
    "                language_list_padded.append(language_model[word])\n",
    "            except KeyError:\n",
    "                unk='<unk>'\n",
    "                #print(\"not found! Assigning Unknown Vector\",  (english_model[unk]).shape)\n",
    "                language_list_padded.append(language_model[unk])\n",
    "        #print(np.array(language_list_padded))\n",
    "        sentence_level_w2vec_list.append((np.array(language_list_padded)))\n",
    "    sentence_level_w2vec=np.array(sentence_level_w2vec_list)\n",
    "    return(sentence_level_w2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=hindi_encoding\n",
    "Y=english_encoding\n",
    "#Y will remain the same.\n",
    "Yoh=np.array(list(map(lambda x: to_categorical(x, num_classes=len(english_dictionary)), Y)))\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this if you want word2vec instead of One hot encoding\n",
    "#Naming it still as X0h and Yoh to avoid changes in too many places further.\n",
    "#Yoh \n",
    "Xoh=sentences_to_w2vec(hindi_encoding,revere_dictionary_hindi,hindi_model)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might also like to get the sentences of only specific length from source as well as target, for example get all sentences which has maximum 5 words and in hindi maximum 8 words. Use below function and feed the length you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=Ndarray with following dimentions (sentence_length, 2)\n",
    "#source_len is the length of language in dataset[0][1]\n",
    "#target_len is the length of language in dataset[0][0]\n",
    "def get_sentences_subset(dataset,source_len,target_len):\n",
    "    limited=dataset\n",
    "    indexes_list=[]\n",
    "    for indexes in range(0,limited.shape[0]):\n",
    "        #print(len(limited[i][0].split()),len(limited[i][1].split()))\n",
    "        eng_len=len(limited[indexes][0].split()) \n",
    "        hin_len=len(limited[indexes][1].split())\n",
    "        state1=(eng_len<target_len)\n",
    "        state2=(hin_len<source_len)\n",
    "        final=state2&state1\n",
    "        #print(eng_len,hin_len,final)\n",
    "        #print(state1,state2,final)\n",
    "        if (final):\n",
    "            indexes_list.append(indexes)\n",
    "    #print(indexes_list,type(indexes_list))\n",
    "    return(limited[indexes_list])"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3.5 with Spark 1.6 (Unsupported)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
